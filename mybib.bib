
@article{bojarski_end_2016,
	title = {End to {End} {Learning} for {Self}-{Driving} {Cars}},
	url = {http://arxiv.org/abs/1604.07316},
	abstract = {We trained a convolutional neural network (CNN) to map raw pixels from a single front-facing camera directly to steering commands. This end-to-end approach proved surprisingly powerful. With minimum training data from humans the system learns to drive in traffic on local roads with or without lane markings and on highways. It also operates in areas with unclear visual guidance such as in parking lots and on unpaved roads. The system automatically learns internal representations of the necessary processing steps such as detecting useful road features with only the human steering angle as the training signal. We never explicitly trained it to detect, for example, the outline of roads. Compared to explicit decomposition of the problem, such as lane marking detection, path planning, and control, our end-to-end system optimizes all processing steps simultaneously. We argue that this will eventually lead to better performance and smaller systems. Better performance will result because the internal components self-optimize to maximize overall system performance, instead of optimizing human-selected intermediate criteria, e.g., lane detection. Such criteria understandably are selected for ease of human interpretation which doesn't automatically guarantee maximum system performance. Smaller networks are possible because the system learns to solve the problem with the minimal number of processing steps. We used an NVIDIA DevBox and Torch 7 for training and an NVIDIA DRIVE(TM) PX self-driving car computer also running Torch 7 for determining where to drive. The system operates at 30 frames per second (FPS).},
	urldate = {2017-03-26},
	journal = {arXiv:1604.07316 [cs]},
	author = {Bojarski, Mariusz and Del Testa, Davide and Dworakowski, Daniel and Firner, Bernhard and Flepp, Beat and Goyal, Prasoon and Jackel, Lawrence D. and Monfort, Mathew and Muller, Urs and Zhang, Jiakai and Zhang, Xin and Zhao, Jake and Zieba, Karol},
	month = apr,
	year = {2016},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Learning, Computer Science - Neural and Evolutionary Computing},
	file = {arXiv.org Snapshot:C\:\\Users\\csten_000\\Dropbox\\Zotero\\storage\\B7KDS3GZ\\1604.html:text/html;Bojarski et al_2016_End to End Learning for Self-Driving Cars.pdf:C\:\\Users\\csten_000\\Dropbox\\Zotero\\storage\\WHP8VA6G\\Bojarski et al_2016_End to End Learning for Self-Driving Cars.pdf:application/pdf}
}

@book{noauthor_universe_2016,
	title = {Universe},
	url = {https://blog.openai.com/universe/},
	abstract = {We're releasing Universe, a software platform for measuring and training an AI's general intelligence across the world's supply of games, websites and other applications. Universe allows an AI agent to use a computer like a human does: by looking at screen pixels and operating a virtual keyboard and mouse. We},
	urldate = {2017-04-03},
	month = dec,
	year = {2016},
	file = {Snapshot:C\:\\Users\\csten_000\\Dropbox\\Zotero\\storage\\6XQ5A5ZQ\\universe.html:text/html}
}

@book{noauthor_deepdrive_2017,
	title = {{DeepDrive}},
	url = {https://web.archive.org/web/20170111195345/http://deepdrive.io/},
	urldate = {2017-04-03},
	month = jan,
	year = {2017}
}

@techreport{pomerleau_alvinn_1989,
	title = {{ALVINN}, an autonomous land vehicle in a neural network},
	url = {https://papers.nips.cc/paper/95-alvinn-an-autonomous-land-vehicle-in-a-neural-network.pdf},
	urldate = {2017-04-03},
	institution = {Carnegie Mellon University, Computer Science Department},
	author = {Pomerleau, Dean A.},
	year = {1989},
	file = {Pomerleau_1989_ALVINN, an autonomous land vehicle in a neural network.pdf:C\:\\Users\\csten_000\\Dropbox\\Zotero\\Pomerleau_1989_ALVINN, an autonomous land vehicle in a neural network.pdf:application/pdf}
}

@inproceedings{lecun_off-road_2005,
	title = {Off-road obstacle avoidance through end-to-end learning},
	url = {https://papers.nips.cc/paper/2847-off-road-obstacle-avoidance-through-end-to-end-learning.pdf},
	urldate = {2017-04-03},
	booktitle = {{NIPS}},
	author = {LeCun, Yann and Muller, Urs and Ben, Jan and Cosatto, Eric and Flepp, Beat},
	year = {2005},
	pages = {739--746},
	file = {LeCun et al_2005_Off-road obstacle avoidance through end-to-end learning.pdf:C\:\\Users\\csten_000\\Dropbox\\Zotero\\LeCun et al_2005_Off-road obstacle avoidance through end-to-end learning.pdf:application/pdf}
}

@book{noauthor_deepdriving_nodate,
	title = {{DeepDriving}},
	url = {http://deepdriving.cs.princeton.edu/},
	urldate = {2017-04-03},
	file = {DeepDriving:C\:\\Users\\csten_000\\Dropbox\\Zotero\\storage\\Z6KR9TT8\\deepdriving.cs.princeton.edu.html:text/html}
}

@book{noauthor_deepdrive_nodate,
	title = {{DeepDrive} - {Vision} model that drives in {GTAV}},
	url = {https://gist.github.com/aiworld/66e69c10c9ec82b299279bc7609544d2},
	abstract = {DeepDrive - Vision model that drives in GTAV},
	urldate = {2017-04-04},
	file = {Snapshot:C\:\\Users\\csten_000\\Dropbox\\Zotero\\storage\\UX2PBDEG\\66e69c10c9ec82b299279bc7609544d2.html:text/html}
}

@book{noauthor_ai-tor/deepgtav_nodate,
	title = {ai-tor/{DeepGTAV}},
	url = {https://github.com/ai-tor/DeepGTAV},
	abstract = {DeepGTAV - A plugin for GTAV that transforms it into a vision-based self-driving car research environment.},
	urldate = {2017-04-04},
	file = {Snapshot:C\:\\Users\\csten_000\\Dropbox\\Zotero\\storage\\ZS698R7P\\DeepGTAV.html:text/html}
}

@book{noauthor_gta_2017,
	title = {{GTA} {V} + {Universe}},
	url = {https://web.archive.org/web/20170111195314/https://openai.com/blog/GTA-V-plus-Universe/},
	urldate = {2017-04-04},
	month = jan,
	year = {2017},
	file = {GTA V + Universe:C\:\\Users\\csten_000\\Dropbox\\Zotero\\storage\\6G3T6FJ6\\GTA-V-plus-Universe.html:text/html}
}

@article{johnson-roberson_driving_2016,
	title = {Driving in the {Matrix}: {Can} {Virtual} {Worlds} {Replace} {Human}-{Generated} {Annotations} for {Real} {World} {Tasks}?},
	shorttitle = {Driving in the {Matrix}},
	url = {http://arxiv.org/abs/1610.01983},
	abstract = {Deep learning has rapidly transformed the state of the art algorithms used to address a variety of problems in computer vision and robotics. These breakthroughs have relied upon massive amounts of human annotated training data. This time consuming process has begun impeding the progress of these deep learning efforts. This paper describes a method to incorporate photo-realistic computer images from a simulation engine to rapidly generate annotated data that can be used for the training of machine learning algorithms. We demonstrate that a state of the art architecture, which is trained only using these synthetic annotations, performs better than the identical architecture trained on human annotated real-world data, when tested on the KITTI data set for vehicle detection. By training machine learning algorithms on a rich virtual world, real objects in real scenes can be learned and classified using synthetic data. This approach offers the possibility of accelerating deep learning's application to sensor-based classification problems like those that appear in self-driving cars. The source code and data to train and validate the networks described in this paper are made available for researchers.},
	urldate = {2017-04-04},
	journal = {arXiv:1610.01983 [cs]},
	author = {Johnson-Roberson, Matthew and Barto, Charles and Mehta, Rounak and Sridhar, Sharath Nittur and Rosaen, Karl and Vasudevan, Ram},
	month = oct,
	year = {2016},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Robotics},
	file = {arXiv.org Snapshot:C\:\\Users\\csten_000\\Dropbox\\Zotero\\storage\\4ZMXEAIJ\\1610.html:text/html;Johnson-Roberson et al_2016_Driving in the Matrix.pdf:C\:\\Users\\csten_000\\Dropbox\\Zotero\\storage\\SB8UPVCU\\Johnson-Roberson et al_2016_Driving in the Matrix.pdf:application/pdf}
}

@inproceedings{chen_deepdriving:_2015,
	title = {Deepdriving: {Learning} affordance for direct perception in autonomous driving},
	shorttitle = {Deepdriving},
	url = {http://www.cv-foundation.org/openaccess/content_iccv_2015/html/Chen_DeepDriving_Learning_Affordance_ICCV_2015_paper.html},
	urldate = {2017-04-04},
	booktitle = {Proceedings of the {IEEE} {International} {Conference} on {Computer} {Vision}},
	author = {Chen, Chenyi and Seff, Ari and Kornhauser, Alain and Xiao, Jianxiong},
	year = {2015},
	pages = {2722--2730},
	file = {Chen et al_2015_Deepdriving.pdf:C\:\\Users\\csten_000\\Dropbox\\Zotero\\Chen et al_2015_Deepdriving.pdf:application/pdf}
}